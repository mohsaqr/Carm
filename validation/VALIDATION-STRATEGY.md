# Carm Factor Analysis — Validation Strategy

## Philosophy

Every Carm statistical function must produce **numerically identical** results to R.
R is the ground truth. If results differ, Carm is wrong until proven otherwise.

Validation is not a one-time check — it is a **permanent, reproducible infrastructure** that runs on demand. Reference data is generated by R, stored as JSON, and consumed by TypeScript harnesses that compare Carm's output value-by-value.

---

## Directory Structure

```
validation/
├── VALIDATION-STRATEGY.md      ← this file
├── reports/                    ← generated HTML cross-validation reports
│   └── fa-crossval-report.html
├── r-reference/                ← R scripts that generate reference data
│   ├── fa-promax-ref.R
│   ├── fa-geomin-ref.R
│   └── fa-real-ref.R
├── ts-harness/                 ← TS scripts that compare Carm vs R
│   ├── fa-full-report.ts
│   └── fa-geomin-crossval.ts
└── data/                       ← JSON reference data (R-generated)
    ├── fa-crossval-data.json       (100 synthetic datasets + R promax results)
    ├── fa-geomin-ref.json          (R geomin results for 100 datasets)
    ├── fa-geomin-real-ref.json     (R geomin results for real 525×31 dataset)
    └── fa-real-crossval-ref.json   (R promax results for real dataset, k=3-6)
```

---

## Current Status (2026-02-26)

| Module | Rotation | Datasets | Pass Rate | Threshold |
|--------|----------|----------|-----------|-----------|
| EFA ML | promax | 100 synthetic | **100/100** | loadMAE ≤ 0.05 |
| EFA ML | geomin | 100 synthetic | **100/100** | loadMAE ≤ 0.05 |
| EFA ML | promax | real 525×31 (k=3,4,5,6) | **4/4** | loadMAE ≤ 0.05 |
| EFA ML | geomin | real 525×31 (k=3,5) | **2/2** | loadMAE ≤ 0.05 |
| Diagnostics | — | 100 synthetic | **100/100** | eigenvalue/KMO/Bartlett ~1e-12 |

---

## Validation Dimensions

### A. Synthetic Data Conditions

The 100 synthetic datasets cover these parameter ranges:

| Parameter | Values | Rationale |
|-----------|--------|-----------|
| n (sample size) | 100, 150, 200, 300, 500 | Small → large n; tests convergence stability |
| p (variables) | 6, 8, 9, 10, 12, 15, 16, 20, 25 | Narrow → wide; tests eigendecomposition scaling |
| k (factors) | 2, 3, 4, 5 | Few → many factors; k≥3 stresses rotation convergence |
| Loading strength | 0.5–0.9 | Weak → strong structure; weak structure tests optimizer robustness |

**Missing conditions to add:**

| Condition | Why | Priority |
|-----------|-----|----------|
| k=1 (single factor) | Rotation should be identity; tests degenerate path | HIGH |
| k=6,7,8 (many factors) | Tests GPFoblq with large T matrices | MEDIUM |
| p=50,100 (high-dimensional) | Tests eigendecomposition and ML convergence at scale | MEDIUM |
| n=50 (very small) | Tests small-sample ML convergence | HIGH |
| n=2000+ (very large) | Tests numerical precision with large matrices | LOW |
| Near-Heywood cases | Items with communality → 1.0; tests clamping | HIGH |
| Cross-loading structure | Items loading on 2+ factors; tests rotation flexibility | MEDIUM |
| Perfect simple structure | Each item loads on exactly 1 factor; tests clean case | LOW |
| Weak/ambiguous structure | Low loadings everywhere; tests parallel analysis & MAP | MEDIUM |

### B. Rotation Methods

Each rotation must be validated independently:

| Rotation | R Reference | Status | Notes |
|----------|-------------|--------|-------|
| **promax** | `psych::fa(rotate="promax")` | DONE 100/100 | Outer Kaiser normalization critical |
| **geomin** | `GPArotation::geominQ(delta=0.01)` | DONE 100/100 | GPFoblq gradient uses L not A |
| **varimax** | `stats::varimax()` | Validated indirectly (promax uses it) | Should have standalone cross-val |
| **oblimin** | `GPArotation::oblimin()` | NOT DONE | Uses same GPFoblq, likely works |
| **quartimin** | `GPArotation::quartimin()` | NOT DONE | gamma=0 oblimin; same GPFoblq |
| **none** | `psych::fa(rotate="none")` | Validated (unrotated matches 100/100) | Tested in geomin diagnostic |

### C. Extraction Methods

| Method | R Reference | Status | Notes |
|--------|-------------|--------|-------|
| **ML** | `psych::fa(fm="ml")` / `factanal()` | DONE 100/100 | Hybrid Jöreskog + Nelder-Mead |
| **PAF** | `psych::fa(fm="pa")` | NOT DONE | Needs separate cross-validation |

### D. Diagnostics

| Metric | R Reference | Status | Tolerance |
|--------|-------------|--------|-----------|
| Eigenvalues | `eigen(cor(X))` | DONE 100/100 | 1e-12 |
| KMO overall | `psych::KMO()$MSA` | DONE 100/100 | 1e-8 |
| KMO per-item | `psych::KMO()$MSAi` | DONE 100/100 | 1e-8 |
| Bartlett χ² | `psych::cortest.bartlett()` | DONE 100/100 | 0.01 |
| Bartlett p | `psych::cortest.bartlett()$p.value` | DONE 100/100 | 1e-8 |
| Velicer MAP | `psych::nfactors()$map` | NOT DONE | Should be exact |
| Parallel analysis | `psych::fa.parallel()` | NOT DONE (stochastic) | Agreement on suggested k |

### E. Fit Indices

| Index | R Reference | Status | Tolerance |
|-------|-------------|--------|-----------|
| χ² | `psych::fa()$STATISTIC` | DONE 100/100 | 10.0 |
| df | `psych::fa()$dof` | DONE 100/100 | 0 (exact) |
| p-value | `psych::fa()$PVAL` | DONE 100/100 | 0.05 |
| RMSEA | `psych::fa()$RMSEA[1]` | DONE 100/100 | 0.02 |
| CFI | `psych::fa()$CFI` | DONE 100/100 | 0.02 |
| TLI | `psych::fa()$TLI` | DONE 100/100 | 0.02 |
| SRMR | `psych::fa()$rms` | DONE 100/100 | 0.01 |
| AIC | `psych::fa()$AIC` | NOT DONE | Needs tolerance check |
| BIC | `psych::fa()$BIC` | NOT DONE | Needs tolerance check |

### F. CFA (Confirmatory Factor Analysis)

| Component | R Reference | Status | Notes |
|-----------|-------------|--------|-------|
| Standardized loadings | `lavaan::cfa()` | NOT DONE | Need lavaan cross-validation |
| SEs | `lavaan::parameterEstimates()$se` | NOT DONE | Numerical Hessian vs exact |
| Fit indices | `lavaan::fitMeasures()` | NOT DONE | Should match closely |
| RMSEA 90% CI | `lavaan::fitMeasures(c("rmsea.ci.lower","rmsea.ci.upper"))` | NOT DONE | Steiger approximation |

### G. Real Datasets

| Dataset | n | p | Source | Status |
|---------|---|---|--------|--------|
| Survey (LOC/CCA/ER/FSI/TW) | 525 | 31 | User's colleague | DONE (promax k=3-6, geomin k=3,5) |
| Holzinger-Swineford 1939 | 301 | 9 | Classic FA benchmark | NOT DONE |
| Big Five Personality | ~2800 | 25 | `psych::bfi` | NOT DONE |
| Thurstone 1947 | 213 | 9 | `psych::Thurstone` | NOT DONE |
| Harman 1976 | 305 | 24 | `psych::Harman74.cor` | NOT DONE |

---

## Validation Procedure

### Step 1: Generate R Reference Data

```bash
cd validation/
Rscript r-reference/fa-promax-ref.R    # → data/fa-crossval-data.json
Rscript r-reference/fa-geomin-ref.R    # → data/fa-geomin-ref.json
Rscript r-reference/fa-real-ref.R      # → data/fa-real-crossval-ref.json
```

Each R script:
1. Generates synthetic data (or loads real CSV)
2. Runs `psych::fa()` or `GPArotation::geominQ()` with exact parameters
3. Extracts all numeric outputs (loadings, communalities, fit indices, etc.)
4. Saves to JSON with 10 significant digits (`toJSON(digits=10)`)

### Step 2: Run Cross-Validation

```bash
cd validation/
npx tsx ts-harness/fa-full-report.ts   # Promax + Geomin + Real → reports/
```

Each TS harness:
1. Loads R reference JSON
2. Runs equivalent Carm analysis with same parameters
3. Handles factor matching (permutation + sign indeterminacy)
4. Computes MAE, max error, pass/fail per dataset
5. Generates HTML report with color-coded tables

### Step 3: Review Report

Open `validation/reports/fa-crossval-report.html` in browser. Check:
- All summary cards show 100% pass (green)
- No red cells in aggregate table
- Per-dataset tables show all-green loadings MAE

---

## Thresholds

| Category | Metric | Threshold | Rationale |
|----------|--------|-----------|-----------|
| **Deterministic** | Eigenvalues, KMO | 1e-8 | Same input → same output, only IEEE-754 rounding |
| **ML extraction** | Uniquenesses, communalities | 0.05 MAE | Different optimizers (L-BFGS-B vs Jöreskog+NM) |
| **Rotation** | Loadings | 0.05 MAE | Non-convex; threshold allows slight optima differences |
| **Fit indices** | χ², RMSEA, CFI, TLI, SRMR | varies | Derived from uniquenesses; propagated error |

**For geomin (now):** All 100 datasets pass at MAE=0.0000 (exact match), so the 0.05 threshold is conservative.

---

## Planned Validation Rounds

### Round 1: Oblimin + Quartimin (Next)
- **R script**: Generate oblimin and quartimin references using `GPArotation::oblimin()` and `GPArotation::quartimin()` on the same 100 synthetic datasets
- **TS harness**: Add rotation='oblimin' and rotation='quartimin' to full report
- **Expected**: Should pass since they use the same GPFoblq as geomin

### Round 2: PAF Extraction
- **R script**: Run `psych::fa(fm="pa")` on 100 synthetic datasets
- **TS harness**: Compare `extraction='paf'` loadings, communalities
- **Expected**: PAF is iterative eigendecomposition; should match closely

### Round 3: CFA vs lavaan
- **R script**: Define CFA models for synthetic datasets, run `lavaan::cfa()`, extract standardized loadings, SEs, fit indices
- **TS harness**: Compare `runCFA()` output
- **Key checks**: Parameter estimates, standard errors (numerical Hessian vs exact), RMSEA 90% CI

### Round 4: Edge Cases
- **Single factor** (k=1): Rotation should be no-op
- **Heywood cases**: Synthetic data designed to produce h² → 1.0
- **Near-singular correlation**: High multicollinearity
- **Perfect simple structure**: Each item loads on exactly 1 factor with λ > 0.7
- **Cross-loaded items**: Items that load on 2 factors equally (λ₁ ≈ λ₂ ≈ 0.4)
- **Small n**: n=30 with k=3 (statistically degenerate but shouldn't crash)

### Round 5: Classic Benchmark Datasets
- **Holzinger-Swineford 1939**: The most widely-used FA benchmark
- **Big Five (psych::bfi)**: 25 items, 5 factors, real personality data
- **Thurstone**: Classic mental abilities dataset
- **Harman74.cor**: 24 variables, correlation matrix directly available

### Round 6: Stress Testing
- **High-dimensional**: p=50, p=100 with n=500
- **Many factors**: k=8, k=10
- **Very large n**: n=5000, n=10000
- **Timing benchmarks**: Compare Carm vs R execution time

---

## Cross-Validation Script Template

### R Reference Generator (template)

```r
#!/usr/bin/env Rscript
suppressPackageStartupMessages({ library(psych); library(GPArotation); library(jsonlite) })

# Load or generate data
X <- ...  # n × p matrix

results <- list()
for (k in c(2, 3, 4, 5)) {
  fa_none <- suppressWarnings(fa(X, nfactors = k, fm = "ml", rotate = "none", warnings = FALSE))

  # Apply rotation
  geo <- geominQ(fa_none$loadings, delta = 0.01)

  results[[as.character(k)]] <- list(
    k = k,
    loadings = unname(matrix(as.numeric(geo$loadings), nrow = ncol(X), ncol = k)),
    phi = unname(as.matrix(geo$Phi)),
    converged = geo$convergence,
    criterion_f = tail(geo$Table[,2], 1)
  )
}

writeLines(toJSON(results, digits = 10, auto_unbox = TRUE), "validation/data/output.json")
```

### TS Harness (template)

```typescript
import { readFileSync } from 'fs'
import { runEFA } from 'carm'

const ref = JSON.parse(readFileSync('validation/data/output.json', 'utf-8'))
const data = JSON.parse(readFileSync('validation/data/dataset.json', 'utf-8'))

for (const [kStr, rr] of Object.entries(ref)) {
  const fa = runEFA(data, {
    nFactors: rr.k, extraction: 'ml', rotation: 'geomin',
    geominDelta: 0.01, variableNames: header,
  })

  const { mae } = matchFactors(rr.loadings, fa.loadings)
  console.log(`k=${rr.k}: ${mae <= 0.05 ? 'PASS' : 'FAIL'} MAE=${mae.toFixed(4)}`)
}
```

---

## Factor Matching Algorithm

Factors are identified up to permutation and sign. The matching algorithm:

1. For all k! permutations of factor columns:
2. For each permutation, determine optimal sign per factor (from dot product sign)
3. Compute loading MAE under that permutation + sign
4. Return minimum-MAE alignment

This is exhaustive for k ≤ 6 (720 permutations × 64 sign combos = 46,080 trials).
For k > 6, use Hungarian algorithm on |correlation| matrix instead.

---

## How to Add a New Validation Round

1. **Create R script** in `validation/r-reference/` that generates reference JSON
2. **Run it**: `Rscript validation/r-reference/new-ref.R` → saves to `validation/data/`
3. **Create TS harness** in `validation/ts-harness/` that loads reference + runs Carm
4. **Run it**: `npx tsx validation/ts-harness/new-crossval.ts`
5. **If it generates HTML**: save to `validation/reports/`
6. **Update this document** with new status row in the tables above

---

## Known Algorithm Differences (R vs Carm)

| Component | R | Carm | Impact |
|-----------|---|------|--------|
| ML optimizer | L-BFGS-B (optim) | Jöreskog gradient + Nelder-Mead | Same optimum, different path |
| Eigendecomposition | LAPACK dsyev | Jacobi iteration | Same result + canonical sign convention |
| Matrix inverse | LAPACK dgesv | LU decomposition | Same result within IEEE-754 |
| Varimax | SVD-based (stats::varimax) | SVD via eigendecomp of B'B | Exact match |
| Promax | psych::kaiser + stats::promax | Outer Kaiser + varimax + Procrustes | Exact match |
| GPFoblq | GPArotation::GPFoblq | Direct translation (gradient, line search) | Exact match |
| PRNG | Mersenne Twister | splitmix32 | Only affects parallel analysis |
